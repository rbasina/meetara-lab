{
  "tara_proven_params": {
    "batch_size": 2,
    "lora_r": 8,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "max_steps": 846,
    "learning_rate": 5e-5,
    "warmup_steps": 100,
    "save_steps": 50,
    "eval_steps": 50,
    "logging_steps": 10,
    "gradient_accumulation_steps": 4,
    "max_grad_norm": 1.0,
    "fp16": true,
    "dataloader_num_workers": 4,
    "remove_unused_columns": false,
    "optim": "adamw_torch",
    "lr_scheduler_type": "cosine",
    "weight_decay": 0.01,
    "adam_beta1": 0.9,
    "adam_beta2": 0.999,
    "adam_epsilon": 1e-8
  },
  "trinity_config": {
    "arc_reactor_efficiency": 0.90,
    "perplexity_intelligence": true,
    "einstein_fusion_multiplier": 5.04,
    "optimization_enabled": true,
    "context_awareness": true,
    "adaptive_routing": true
  },
  "model_tier_mappings": {
    "lightning": {
      "model_path": "microsoft/Phi-3.5-mini-instruct",
      "cost_per_hour": 0.25,
      "recommended_gpu": "T4",
      "batch_size": 8,
      "sequence_length": 128,
      "performance_tier": "lightning"
    },
    "fast": {
      "model_path": "microsoft/Phi-3.5-mini-instruct", 
      "cost_per_hour": 0.50,
      "recommended_gpu": "T4",
      "batch_size": 6,
      "sequence_length": 256,
      "performance_tier": "fast"
    },
    "balanced": {
      "model_path": "microsoft/Phi-3.5-mini-instruct",
      "cost_per_hour": 1.00,
      "recommended_gpu": "V100",
      "batch_size": 4,
      "sequence_length": 512,
      "performance_tier": "balanced"
    },
    "quality": {
      "model_path": "microsoft/Phi-3.5-mini-instruct",
      "cost_per_hour": 1.50,
      "recommended_gpu": "A100",
      "batch_size": 2,
      "sequence_length": 1024,
      "performance_tier": "quality"
    }
  },
  "category_model_mappings": {
    "healthcare": "quality",
    "specialized": "quality",
    "business": "balanced",
    "education": "balanced",
    "technology": "balanced",
    "daily_life": "fast",
    "creative": "lightning"
  },
  "trinity_architecture": {
    "version": "3.0",
    "arc_reactor_optimization": true,
    "perplexity_intelligence": true,
    "einstein_fusion": true
  },
  "compression_config": {
    "quantization_levels": [
      {
        "type": "Q2_K",
        "size_mb": 0.03,
        "description": "Ultra-compressed (30KB)",
        "use_cases": ["mobile", "edge", "ultra_fast"]
      },
      {
        "type": "Q4_K_M", 
        "size_mb": 8.3,
        "description": "Standard (8.3MB)",
        "use_cases": ["production", "balanced", "default"]
      },
      {
        "type": "Q5_K_S",
        "size_mb": 0.1,
        "description": "High-quality compressed (100KB)",
        "use_cases": ["quality", "server", "research"]
      }
    ],
    "default_quantization": "Q4_K_M",
    "compression_types": ["standard", "sparse", "hybrid", "distilled"],
    "target_sizes": {
      "mobile": 0.03,
      "edge": 0.1,
      "standard": 8.3,
      "server": 25.0,
      "research": 100.0
    }
  },
  "model_tiers": {
    "tier_1": {
      "models": ["microsoft/DialoGPT-small", "microsoft/DialoGPT-medium"],
      "lora_r": 4,
      "learning_rate": 0.0001,
      "max_steps": 500
    },
    "tier_2": {
      "models": ["microsoft/DialoGPT-medium", "microsoft/Phi-3.5-mini-instruct"],
      "lora_r": 6,
      "learning_rate": 0.0003,
      "max_steps": 1000
    },
    "tier_3": {
      "models": ["microsoft/Phi-3.5-mini-instruct", "microsoft/DialoGPT-large"],
      "lora_r": 8,
      "learning_rate": 0.0005,
      "max_steps": 1500
    }
  },
  "domain_categories": {
    "healthcare": {
      "domains": ["general_health", "mental_health", "nutrition", "fitness", "sleep", "stress_management", "preventive_care", "chronic_conditions", "medication_management", "emergency_care", "women_health", "senior_health"],
      "base_model": "microsoft/Phi-3.5-mini-instruct",
      "tier": "tier_2",
      "intelligence_patterns": ["symptom_analysis", "treatment_recommendations", "prevention_strategies"]
    },
    "daily_life": {
      "domains": ["parenting", "relationships", "personal_assistant", "communication", "home_management", "shopping", "planning", "transportation", "time_management", "decision_making", "conflict_resolution", "work_life_balance"],
      "base_model": "microsoft/DialoGPT-medium",
      "tier": "tier_1",
      "intelligence_patterns": ["daily_planning", "relationship_advice", "problem_solving"]
    },
    "business": {
      "domains": ["entrepreneurship", "marketing", "sales", "customer_service", "project_management", "team_leadership", "financial_planning", "operations", "hr_management", "strategy", "consulting", "legal_business"],
      "base_model": "microsoft/Phi-3.5-mini-instruct",
      "tier": "tier_3",
      "intelligence_patterns": ["strategic_analysis", "decision_support", "process_optimization"]
    },
    "education": {
      "domains": ["academic_tutoring", "skill_development", "career_guidance", "exam_preparation", "language_learning", "research_assistance", "study_techniques", "educational_technology"],
      "base_model": "microsoft/DialoGPT-medium",
      "tier": "tier_2",
      "intelligence_patterns": ["learning_assessment", "knowledge_transfer", "skill_building"]
    },
    "creative": {
      "domains": ["writing", "storytelling", "content_creation", "social_media", "design_thinking", "photography", "music", "art_appreciation"],
      "base_model": "microsoft/DialoGPT-medium",
      "tier": "tier_1",
      "intelligence_patterns": ["creative_inspiration", "content_generation", "artistic_guidance"]
    },
    "technology": {
      "domains": ["programming", "ai_ml", "cybersecurity", "data_analysis", "tech_support", "software_development"],
      "base_model": "microsoft/Phi-3.5-mini-instruct",
      "tier": "tier_3",
      "intelligence_patterns": ["technical_analysis", "problem_solving", "code_optimization"]
    },
    "specialized": {
      "domains": ["legal", "financial", "scientific_research", "engineering"],
      "base_model": "microsoft/Phi-3.5-mini-instruct",
      "tier": "tier_3",
      "intelligence_patterns": ["expert_analysis", "compliance_checking", "specialized_reasoning"]
    }
  }
} 