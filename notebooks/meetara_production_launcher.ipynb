{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeeTARA Lab - Production Training Launcher",
    "## 🚀 Trinity Architecture GPU Training for All 62 Domains",
    "",
    "This notebook runs the production launcher script to train all 62 domains using Google Colab's GPU.",
    "",
    "### Performance Targets:",
    "- **T4 GPU**: 37x faster than CPU",
    "- **V100 GPU**: 75x faster than CPU",
    "- **A100 GPU**: 151x faster than CPU",
    "- **Quality**: 101% validation scores",
    "- **Budget**: <$50/month for all domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability",
    "!nvidia-smi",
    "",
    "import torch",
    "print(f\"\\n🔥 CUDA Available: {torch.cuda.is_available()}\")",
    "if torch.cuda.is_available():",
    "    gpu_name = torch.cuda.get_device_name(0)",
    "    print(f\"⚡ GPU: {gpu_name}\")",
    "    if \"T4\" in gpu_name:",
    "        speed_factor = \"37x faster\"",
    "    elif \"V100\" in gpu_name:",
    "        speed_factor = \"75x faster\"  ",
    "    elif \"A100\" in gpu_name:",
    "        speed_factor = \"151x faster\"",
    "    else:",
    "        speed_factor = \"GPU acceleration\"",
    "    print(f\"🎯 Expected Speed: {speed_factor} than CPU baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Required Dependencies",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
    "!pip install transformers datasets peft accelerate bitsandbytes",
    "!pip install huggingface_hub wandb tensorboard",
    "!pip install pyyaml tqdm rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the MeeTARA Lab repository",
    "!git clone https://github.com/rbasina/meetara-lab.git",
    "%cd meetara-lab",
    "",
    "# Configure environment",
    "import os",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the production launcher script",
    "!cd cloud-training && python production_launcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the generated models",
    "!ls model-factory/trinity_gguf_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file of the models for easy download",
    "!zip -r trinity_gguf_models.zip model-factory/trinity_gguf_models",
    "",
    "from google.colab import files",
    "files.download('trinity_gguf_models.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
