# Cell 1: Markdown
# MeeTARA Lab - Production Training Launcher
## ðŸš€ Trinity Architecture GPU Training for All 62 Domains

This notebook runs the production launcher script to train all 62 domains using Google Colab's GPU.

### Performance Targets:
- **T4 GPU**: 37x faster than CPU
- **V100 GPU**: 75x faster than CPU
- **A100 GPU**: 151x faster than CPU
- **Quality**: 101% validation scores
- **Budget**: <$50/month for all domains

### Instructions:
1. Upload this notebook to Google Colab
2. Select Runtime > Change runtime type > GPU
3. Run all cells
4. Download the generated GGUF models

# Cell 2: Code
# Check GPU availability
!nvidia-smi

import torch
print(f"\nðŸ”¥ CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f"âš¡ GPU: {gpu_name}")
    if "T4" in gpu_name:
        speed_factor = "37x faster"
    elif "V100" in gpu_name:
        speed_factor = "75x faster"  
    elif "A100" in gpu_name:
        speed_factor = "151x faster"
    else:
        speed_factor = "GPU acceleration"
    print(f"ðŸŽ¯ Expected Speed: {speed_factor} than CPU baseline")

# Cell 3: Code
# Install Required Dependencies
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install transformers datasets peft accelerate bitsandbytes
!pip install huggingface_hub wandb tensorboard
!pip install gguf llama-cpp-python
!pip install speechbrain librosa soundfile
!pip install opencv-python Pillow numpy
!pip install pyyaml tqdm rich

# Cell 4: Code
# Clone the MeeTARA Lab repository
!git clone https://github.com/rbasina/meetara-lab.git
%cd meetara-lab

# Configure environment
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'

# Cell 5: Code
# Create MCP protocol module (if not already present)
!mkdir -p trinity-core/agents

%%writefile trinity-core/agents/mcp_protocol.py
"""
MeeTARA Lab - MCP Protocol for Agent Communication
Multi-agent coordination protocol for Trinity Architecture
"""

import asyncio
from enum import Enum, auto
from typing import Dict, Any, List, Optional, Callable
import time
import uuid

class AgentType(Enum):
    """Types of agents in the system"""
    CONDUCTOR = auto()  # Training conductor
    CREATOR = auto()    # GGUF creator
    OPTIMIZER = auto()  # GPU optimizer
    VALIDATOR = auto()  # Quality validator
    MONITOR = auto()    # System monitor

class MessageType(Enum):
    """Types of messages in the MCP protocol"""
    REGISTER = auto()    # Agent registration
    COMMAND = auto()     # Command message
    STATUS = auto()      # Status update
    RESULT = auto()      # Result message
    ERROR = auto()       # Error message

class MCPMessage:
    """Message in the MCP protocol"""
    
    def __init__(self, msg_type: MessageType, sender: AgentType, 
                 receiver: Optional[AgentType] = None, payload: Dict[str, Any] = None):
        self.id = str(uuid.uuid4())
        self.type = msg_type
        self.sender = sender
        self.receiver = receiver
        self.payload = payload or {}
        self.timestamp = time.time()
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert message to dictionary"""
        return {
            "id": self.id,
            "type": self.type.name,
            "sender": self.sender.name,
            "receiver": self.receiver.name if self.receiver else None,
            "payload": self.payload,
            "timestamp": self.timestamp
        }

class BaseAgent:
    """Base class for all agents in the system"""
    
    def __init__(self, agent_type: AgentType, mcp=None):
        self.agent_type = agent_type
        self.mcp = mcp
        self.id = str(uuid.uuid4())
    
    async def handle_message(self, message: MCPMessage) -> Optional[MCPMessage]:
        """Handle incoming message"""
        print(f"Agent {self.agent_type.name} received message of type {message.type.name}")
        return None
    
    async def send_message(self, msg_type: MessageType, receiver: Optional[AgentType] = None, 
                          payload: Dict[str, Any] = None) -> str:
        """Send message through MCP"""
        if self.mcp:
            message = MCPMessage(msg_type, self.agent_type, receiver, payload)
            await self.mcp.send_message(message)
            return message.id
        else:
            print(f"Warning: Agent {self.agent_type.name} has no MCP connection")
            return ""

class MCPProtocol:
    """Multi-agent Coordination Protocol"""
    
    def __init__(self):
        self.agents: Dict[AgentType, BaseAgent] = {}
        self.message_queue = asyncio.Queue()
        self.running = False
        self.processor_task = None
    
    async def register_agent(self, agent: BaseAgent):
        """Register an agent with the MCP"""
        self.agents[agent.agent_type] = agent
        print(f"âœ… Agent {agent.agent_type.name} registered with MCP")
    
    async def send_message(self, message: MCPMessage):
        """Send a message through the MCP"""
        await self.message_queue.put(message)
    
    async def process_messages(self):
        """Process messages in the queue"""
        while self.running:
            try:
                message = await self.message_queue.get()
                
                if message.receiver:
                    # Directed message
                    if message.receiver in self.agents:
                        await self.agents[message.receiver].handle_message(message)
                    else:
                        print(f"Warning: No agent of type {message.receiver.name} registered")
                else:
                    # Broadcast message
                    for agent_type, agent in self.agents.items():
                        if agent_type != message.sender:
                            await agent.handle_message(message)
                
                self.message_queue.task_done()
            except Exception as e:
                print(f"Error processing message: {e}")
    
    def start(self):
        """Start the MCP"""
        self.running = True
        self.processor_task = asyncio.create_task(self.process_messages())
        print("âœ… MCP started")
    
    def stop(self):
        """Stop the MCP"""
        self.running = False
        if self.processor_task:
            self.processor_task.cancel()
        print("âœ… MCP stopped")

# Singleton instance
_mcp_instance = None

def get_mcp_protocol() -> MCPProtocol:
    """Get the singleton MCP instance"""
    global _mcp_instance
    if _mcp_instance is None:
        _mcp_instance = MCPProtocol()
    return _mcp_instance

# Cell 6: Code
# Run the production launcher script
!cd cloud-training && python production_launcher.py

# Cell 7: Code
# Check the generated models
!ls model-factory/trinity_gguf_models

# Cell 8: Code
# Create a zip file of the models for easy download
!zip -r trinity_gguf_models.zip model-factory/trinity_gguf_models

from google.colab import files
files.download('trinity_gguf_models.zip') 